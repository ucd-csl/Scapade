{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S-capade Single Phoneme Sequence Correction Demo\n",
    "This file is a quick implementation of the S-capade method which acoustic edit distance and phoneme sequence representations of misspellings to attempt corrections. To generate the phoneme sequence representation of the misspellings, the CMU dictionary is used. To generate candidate lists using symmetric deletes (for speed), an adaption of SymSpell/SymSpellPy is used. This is a demo only, and adapated from the core code located in text_processing.dataset_processing.symspell_scapade. Usually, you would pass entire word lists to the tool, in the format  \n",
    "\n",
    "\\\\$accommodate  \n",
    "accomodate  \n",
    "acommadate  \n",
    "\\\\$accord\n",
    "acord  \n",
    "\\\\$acquaintance  \n",
    "aquantance  \n",
    "\n",
    "Where \\\\$ indicates the target correction and everything below this until the next \\\\$ indicates the misspellings of this target word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing.dataset_processing import symspell_scapade\n",
    "from pathlib import Path\n",
    "from symspellpy_scapade import symspellscapade\n",
    "import pkg_resources\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load S-capade method - only need to do this once, this takes the longest time at outset\n",
    "SymSpell = symspellscapade.SymSpell\n",
    "Verbosity = symspellscapade.Verbosity\n",
    "scapade = SymSpell(max_dictionary_edit_distance=2, prefix_length=15)\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy_scapade\", \"cmu_frequency_added.csv\")\n",
    "scapade.load_dictionary(dictionary_path, term_index=1, count_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough implementation of the function in text_processing.dataset_processing.symspell_scapade\n",
    "# The function in that dataset is used for processing word lists from datasets (the five for the paper)\n",
    "# This is a quick implementation of it to demonstrate how it works just with single phoneme sequence misspellings\n",
    "# You can generate phoneme sequences to pass to it using http://www.speech.cs.cmu.edu/cgi-bin/cmudict or\n",
    "# you write a shell script to work beside this example so you only need to pass word misspellings in and get \n",
    "# corrections out\n",
    "def correction(scapade, phoneme_sequence):\n",
    "    misspelling = phoneme_sequence\n",
    "    suggestions = scapade.lookup(misspelling, Verbosity.ALL)\n",
    "    input_path_csv = Path(\"input_files/\") / \"cmu_frequency_added.csv\"\n",
    "    df = pd.read_csv(input_path_csv, names=['word', 'seq', 'count'])\n",
    "    correction_dict =  {misspelling:{\"suggested_correction\":\"\", \"candidates\":[]}}\n",
    "\n",
    "    for suggestion in suggestions:\n",
    "        if len(correction_dict[misspelling]['candidates']) >= 10:\n",
    "            break\n",
    "        current_seq = str(suggestion).split(',')[0]\n",
    "        df_slice = df[df['seq'] == current_seq].sort_values(by=['count'], ascending=False)\n",
    "        if correction_dict[misspelling]['suggested_correction'] == '' and df_slice.iloc[0]['count'] >= 1:\n",
    "            correction_dict[misspelling]['suggested_correction'] = df_slice.iloc[0]['word']\n",
    "        if len(correction_dict[misspelling]['suggested_correction']) > 0 and \\\n",
    "        len(correction_dict[misspelling]['candidates']) <= 10:\n",
    "            df_slice = df_slice[df_slice['count'] > 1]\n",
    "            correction_dict[misspelling]['candidates'] += (list(df_slice[:5]['word']))\n",
    "    return correction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EH N IY B AH D IY': {'suggested_correction': 'anybody', 'candidates': ['anybody', 'nobody', 'enabled']}}\n"
     ]
    }
   ],
   "source": [
    "# anybody - enybody EH N IY B AH D IY\n",
    "print(correction(scapade, \"EH N IY B AH D IY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EH G S AE M P AH L': {'suggested_correction': 'example', 'candidates': ['example', 'sample']}}\n"
     ]
    }
   ],
   "source": [
    "# example - egsample EH G S AE M P AH L\n",
    "print(correction(scapade, \"EH G S AE M P AH L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N EH S AH K EH R IY AH L IY': {'suggested_correction': 'necessarily', 'candidates': ['necessarily']}}\n"
     ]
    }
   ],
   "source": [
    "# necessarily N EH S AH K EH R IY AH L IY\n",
    "print(correction(scapade,\"N EH S AH K EH R IY AH L IY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
