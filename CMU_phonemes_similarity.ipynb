{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.4387146091200425\n",
      "Correct word found : 2190\n",
      "Guess word not in frequency or CMU dict : 1\n",
      "Bad correction : 31821\n",
      "34012\n",
      "34012\n",
      "Guess word was in close words 6431 times, ie in 18.907476553082645 percent of the case\n",
      "New correction percentage 6.439093234541766\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import birkbeck_parser\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "# compare two seqs of phon\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    # d = table of actual scores\n",
    "    # e = keeps track of operations\n",
    "    return d, e\n",
    "\n",
    "# individual phonemes\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "# looks to find the smallest edit distance backwards through the matrix\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "# uses back trace to align phonemes \n",
    "# mapping the two diff strings\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "# pretty print of alignment table\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "# end of days# ----\n",
    "\n",
    "#Decalaration and importation of the structures required for this script\n",
    "birkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = birkbeck_parser.reverse_dict\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('cmu_results&misspellings.csv') # results from g2p-seq2seq and the birkbeck data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.3:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import birkbeck_parser\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(\"acoustic_similarity.csv\", index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this script\n",
    "birkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = birkbeck_parser.reverse_dict\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('cmu_results&misspellings.csv') # results from g2p-seq2seq and the birkbeck data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes_dist_list=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.7 :\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "                    phonemes_dist_list.append([i,dist])\n",
    "    #Sort close seq of phonemes and keep the 20 best\n",
    "    if (len(phonemes_dist_list)>20):\n",
    "        close=[] #future liste avec uniquement les 10 phonemes les plus proches\n",
    "        sort=sorted(phonemes_dist_list, key=lambda tup: tup[1])\n",
    "        close_phonemes_list= sort[:20] # keep only the best first elements\n",
    "        for k in range (0, len(close_phonemes_list)):\n",
    "            close.append(close_phonemes_list[0]) # only add the phonemes but not the distance\n",
    "        close_seq_of_phonemes_dict[misspelling]=close\n",
    "    else :\n",
    "        close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "print(\"Retrieved all the close phonemes within an edit distance of 0.7\")\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in list(cmu_dict):\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "print(\"Retrieved the corresponding words\")  \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved the corresponding words\n",
      "correction percentage :  0.5439096815923323\n",
      "Correct word found : 185\n",
      "Guess word not in frequency or CMU dict : 1\n",
      "Bad correction : 33826\n",
      "34012\n",
      "34012\n",
      "Guess word was in close words 263 times, ie in 0.7732337635609914 percent of the case\n",
      "New correction percentage 0.5439416659316103\n"
     ]
    }
   ],
   "source": [
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic = 0\n",
    "frequency = 0\n",
    "guess_dict = {} # dictionary with only the misspelled word and the guess\n",
    "close_dict = {} # dictionary with all the close words\n",
    "not_in_freq_dict = {}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list = [] #store all the close words \n",
    "    phonemes_list = close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot = \"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in list(cmu_dict):\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot = guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling] = words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "print(\"Retrieved the corresponding words\")  \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck = 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words = close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words = open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i = 0\n",
    "match = 0\n",
    "no_match = 0\n",
    "bad_corr = 0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i += 1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match += 1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr += 1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match += 1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  7.738217740275777\n",
      "Correct word found : 5422\n",
      "Guess word not in frequency or CMU dict : 4\n",
      "Bad correction : 130622\n",
      "136048\n",
      "136048\n",
      "Guess word was in close words 8363 times, ie in 24.587657660306352 percent of the case\n",
      "New correction percentage 3.9854752874070156\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import birkbeck_parser\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this script\n",
    "birkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = birkbeck_parser.reverse_dict\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('cmu_results&misspellings.csv') # results from g2p-seq2seq and the birkbeck data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.5:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  5.615499955899215\n",
      "Correct word found : 1910\n",
      "Guess word not in frequency or CMU dict : 1\n",
      "Bad correction : 32101\n",
      "34012\n",
      "34012\n",
      "Guess word was in close words 12027 times, ie in 35.360009408167464 percent of the case\n",
      "New correction percentage 5.61583017259122\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import birkbeck_parser\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this script\n",
    "birkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = birkbeck_parser.reverse_dict\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('cmu_results&misspellings.csv') # results from g2p-seq2seq and the birkbeck data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.7:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  5.697821421221297\n",
      "Correct word found : 1938\n",
      "Guess word not in frequency or CMU dict : 1\n",
      "Bad correction : 32073\n",
      "34012\n",
      "34012\n",
      "Guess word was in close words 12893 times, ie in 37.90609472848617 percent of the case\n",
      "New correction percentage 5.6981564787862755\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import birkbeck_parser\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this script\n",
    "birkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = birkbeck_parser.reverse_dict\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('cmu_results&misspellings.csv') # results from g2p-seq2seq and the birkbeck data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 1:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"cmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('cmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"cmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('cmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('cmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('cmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('cmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  9.70873786407767\n",
      "Correct word found : 70\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 578\n",
      "648\n",
      "648\n",
      "Guess word was in close words 224 times, ie in 31.06796116504854 percent of the case\n",
      "New correction percentage 10.802469135802468\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.5:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.38002773925104\n",
      "Correct word found : 46\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 602\n",
      "648\n",
      "648\n",
      "Guess word was in close words 258 times, ie in 35.78363384188627 percent of the case\n",
      "New correction percentage 7.098765432098765\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.7:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  9.57004160887656\n",
      "Correct word found : 69\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 579\n",
      "648\n",
      "648\n",
      "Guess word was in close words 177 times, ie in 24.549237170596395 percent of the case\n",
      "New correction percentage 10.648148148148149\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.3:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  9.57004160887656\n",
      "Correct word found : 69\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 579\n",
      "648\n",
      "648\n",
      "Guess word was in close words 179 times, ie in 24.826629680998614 percent of the case\n",
      "New correction percentage 10.648148148148149\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.4:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.51872399445215\n",
      "Correct word found : 116\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 1180\n",
      "1296\n",
      "1296\n",
      "Guess word was in close words 258 times, ie in 35.78363384188627 percent of the case\n",
      "New correction percentage 8.950617283950617\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.6:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.657420249653259\n",
      "Correct word found : 48\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 600\n",
      "648\n",
      "648\n",
      "Guess word was in close words 257 times, ie in 35.64493758668516 percent of the case\n",
      "New correction percentage 7.4074074074074066\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.55:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  9.57004160887656\n",
      "Correct word found : 69\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 579\n",
      "648\n",
      "648\n",
      "Guess word was in close words 179 times, ie in 24.826629680998614 percent of the case\n",
      "New correction percentage 10.648148148148149\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.45:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.796116504854369\n",
      "Correct word found : 118\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 1178\n",
      "1296\n",
      "1296\n",
      "Guess word was in close words 255 times, ie in 35.367545076282944 percent of the case\n",
      "New correction percentage 9.104938271604938\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.52:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.38002773925104\n",
      "Correct word found : 46\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 602\n",
      "648\n",
      "648\n",
      "Guess word was in close words 260 times, ie in 36.061026352288486 percent of the case\n",
      "New correction percentage 7.098765432098765\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 0.9:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "matrix name:  acoustic_similarity.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction percentage :  6.38002773925104\n",
      "Correct word found : 46\n",
      "Guess word not in frequency or CMU dict : 0\n",
      "Bad correction : 602\n",
      "648\n",
      "648\n",
      "Guess word was in close words 264 times, ie in 36.615811373092924 percent of the case\n",
      "New correction percentage 7.098765432098765\n"
     ]
    }
   ],
   "source": [
    "#CMU with phoneme edit distance\n",
    "\n",
    "import sys\n",
    "import stringdist\n",
    "from string import digits\n",
    "import hollbrook_structures\n",
    "import csv\n",
    "import data_structures\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#EMMA'S EDIT DISTANCE FOR PHONEMES\n",
    "#similarity matrix \n",
    "similarities = pd.read_csv(input('matrix name: '), index_col=0)\n",
    "\n",
    "#cost of insertion/deletion\n",
    "idc=0.5\n",
    "\n",
    "def compare(string1, string2):\n",
    "    r = string1\n",
    "    h = string2\n",
    "\n",
    "\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=float)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "    e = np.zeros((len(r)+1)*(len(h)+1), dtype=object)\n",
    "    e = e.reshape((len(r)+1, len(h)+1))\n",
    "\n",
    "\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    d[0][0] = 0\n",
    "                    e[0][j] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i][j-1] + idc\n",
    "                    e[0][j] = (0,0,1)\n",
    "            elif j == 0:\n",
    "                if i == 0:\n",
    "                    e[i][0] = (0,0,0)\n",
    "                else:\n",
    "                    d[i][j] = d[i-1][j] + idc\n",
    "                    e[i][0] = (1,0,0)\n",
    "\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "                e[i][j] = (0, 1, 0)                \n",
    "            else:\n",
    "                #some random extra stuff in here that doesn't get used - could clean up but works as is\n",
    "                sub = ((d[i-1][j-1] + (score(r[i-1], h[j-1]))) , (str(e[i-1][j-1]) + 'substitution ' + str(j-1) + ', '))\n",
    "                dell = (d[i-1][j] +idc, (str(e[i][j-1]) + 'deletion ' + str(j-1) + ' ,'))\n",
    "                if j >= len(h):\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                else:\n",
    "                    ins = (d[i][j-1] +idc, (str(e[i-1][j]) + 'insertion ' + str(j) + ' ,'))\n",
    "                d[i][j] = min(sub, ins, dell)[0]\n",
    "                e[i][j] = (dell[0]==d[i][j], sub[0]==d[i][j], ins[0]==d[i][j]) * 1    \n",
    "    return d, e\n",
    "\n",
    "def score(l1, l2):\n",
    "    return similarities[str(l1)][str(l2)]\n",
    "\n",
    "#naive_backtrace and align code taken from the internet - uses the backtrace to find \n",
    "#the optimum path and alignment\n",
    "#https://giov.dev/2016/01/minimum-edit-distance-in-python.html\n",
    "\n",
    "def naive_backtrace(B_matrix):\n",
    "\n",
    "    i, j = B_matrix.shape[0]-1, B_matrix.shape[1]-1\n",
    "    backtrace_idxs = [(i, j)]\n",
    "    while (i, j) != (0, 0):\n",
    "        if B_matrix[i,j][1]:\n",
    "            i, j = i-1, j-1\n",
    "        elif B_matrix[i,j][0]:\n",
    "            i, j = i-1, j\n",
    "        elif B_matrix[i,j][2]:\n",
    "            i, j = i, j-1\n",
    "        backtrace_idxs.append((i,j))\n",
    "\n",
    "    return backtrace_idxs\n",
    "\n",
    "def align(word_1, word_2, bt):\n",
    "    \n",
    "    aligned_word_1 = []\n",
    "    aligned_word_2 = []\n",
    "    operations = []\n",
    "\n",
    "    backtrace = bt[::-1]  # make it a forward trace\n",
    "\n",
    "    for k in range(len(backtrace) - 1): \n",
    "        i_0, j_0 = backtrace[k]\n",
    "        i_1, j_1 = backtrace[k+1]\n",
    "\n",
    "        w_1_letter = None\n",
    "        w_2_letter = None\n",
    "        op = None\n",
    "\n",
    "        if i_1 > i_0 and j_1 > j_0:  # either substitution or no-op\n",
    "            if word_1[i_0] == word_2[j_0]:  # no-op, same symbol\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \" \"\n",
    "            else:  # cost increased: substitution\n",
    "                w_1_letter = word_1[i_0]\n",
    "                w_2_letter = word_2[j_0]\n",
    "                op = \"s\"\n",
    "        elif i_0 == i_1:  # insertion\n",
    "            w_1_letter = \" \"\n",
    "            w_2_letter = word_2[j_0]\n",
    "            op = \"i\"\n",
    "        else: #  j_0 == j_1,  deletion\n",
    "            w_1_letter = word_1[i_0]\n",
    "            w_2_letter = \" \"\n",
    "            op = \"d\"\n",
    "\n",
    "        aligned_word_1.append(w_1_letter)\n",
    "        aligned_word_2.append(w_2_letter)\n",
    "        operations.append(op)\n",
    "    \n",
    "    \n",
    "\n",
    "    return aligned_word_1, aligned_word_2, operations\n",
    "\n",
    "\n",
    "def make_table(alignment):\n",
    "    row1=[]\n",
    "    row2=[]\n",
    "    row3=[]\n",
    "    for i,j,k in alignment:\n",
    "        row1.append(i)\n",
    "        row2.append(j)\n",
    "        row3.append(k)\n",
    "    table=[row1, row2, row3]\n",
    "    return table\n",
    "    \n",
    "def align_and_score(word1, word2):\n",
    "    d, e = compare(word1, word2)\n",
    "    bt = naive_backtrace(e)\n",
    "    a, b, c =  (align(word1, word2, bt))\n",
    "    alignment = (list(zip(a,b,c)))\n",
    "    x,y = (d.shape)\n",
    "    score = (d[x-1][y-1]) \n",
    "    table = make_table(alignment)\n",
    "    return score\n",
    "\n",
    "    \n",
    "\n",
    "#Decalaration and importation of the structures required for this scriptbirkbeck_dict = birkbeck_parser.birkbeck_dict\n",
    "reverse_dict = hollbrook_structures.hollbrook_reverse\n",
    "\n",
    "cmu_dict = data_structures.cmu_dict   # cmu_dict[phonemes]=word\n",
    "cmu_dict2 = data_structures.cmu_dict2  # cmu_dict2[word]= phonemes\n",
    "cmu_phones = data_structures.cmu_phones # list of sequence of phonemes\n",
    "frequency_dict = data_structures.frequency_dict #frequency_dict[word]=frequency (which is a STRING not an INT)\n",
    "\n",
    "f = open('hollbrook_miss_phi.csv') # results from g2p-seq2seq and the hollbrook data set\n",
    "csv_f = csv.reader(f)\n",
    "results_dict = {}\n",
    "\n",
    "#creating dictionary of misspellings and cmu dict phonemes of misspellings\n",
    "for row in csv_f:\n",
    "    results_dict[row[0]] = row[1] # results_dict[misspelled word]=sequence of phonemes\n",
    "    \n",
    "# 1 - Getting all closes phonemes of the misspelled word\n",
    "\n",
    "#For each misspelled word, we get a list of sequences of phonemes within an edit distance of 2\n",
    "#Each sequence of phonemes must start and end with the same phoneme as the missepelled word's sequence of phonemes\n",
    "close_seq_of_phonemes_dict={}\n",
    "for misspelling in list(results_dict)[0:]: #results_dict len = 34013\n",
    "    close_seq_of_phonemes=[]\n",
    "    phonemes = results_dict.get(misspelling) #phonemes seq associated to the misspelling\n",
    "    phonemes_list=phonemes.split(\" \")\n",
    "    close_seq_of_phonemes.append(phonemes) #make sure the list of close phonemes also contains the misspelled word's phonemes\n",
    "    for i in cmu_phones:\n",
    "        j=i.split(\" \") #to compare the phonemes and not each caracter  \n",
    "        if j[:1]==phonemes_list[:1]:\n",
    "            if j[-1]==phonemes_list[-1]:\n",
    "                dist = align_and_score(phonemes_list, j) # Emma's distance for phonemes\n",
    "                if dist <= 1:\n",
    "                    close_seq_of_phonemes.append(i)\n",
    "    close_seq_of_phonemes_dict[misspelling]=close_seq_of_phonemes\n",
    "\n",
    "# 2 - Getting the corresponding word for the most common sequence of phonemes\n",
    "nbwords_in_cmu = 0\n",
    "words_in_freq_dic =0\n",
    "frequency=0\n",
    "guess_dict={} # dictionary with only the misspelled word and the guess\n",
    "close_dict={} # dictionary with all the close words\n",
    "not_in_freq_dict={}\n",
    "for misspelling in list(close_seq_of_phonemes_dict):\n",
    "    words_list=[] #store all the close words \n",
    "    phonemes_list=close_seq_of_phonemes_dict.get(misspelling)\n",
    "    popular_seq = phonemes_list[0] # the first et ie the misspelled word  sequence of phonemes\n",
    "    max_frequency = 0 #frequency of the word\n",
    "    popular_mot=\"mot\"\n",
    "    for seq in phonemes_list:\n",
    "        if seq in cmu_dict:\n",
    "            guess = cmu_dict.get(seq)\n",
    "            words_list.append(guess.lower())\n",
    "            if guess in frequency_dict:\n",
    "                frequency = int(frequency_dict.get(guess)) # get the frequency associated to the guessed word\n",
    "                if (frequency > max_frequency):\n",
    "                    popular_mot= guess\n",
    "                    max_frequency = frequency \n",
    "            else:\n",
    "                with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                    Fwriter =csv.writer(csvfile, delimiter=',')\n",
    "                    Fwriter.writerow([misspelling] + ['frequency'])\n",
    "        else:\n",
    "            with open(\"HBKcmu_no_correction.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([misspelling] + ['cmu'])\n",
    "                \n",
    "    close_dict[misspelling]=words_list\n",
    "    guess_dict[misspelling] = popular_mot\n",
    "\"\"\" if(popular_mot != \"mot\"): #otherwise words that are either not in CMU nor frequency are added\n",
    "        guess_dict[misspelling] = popular_mot\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "#dictionary with correct spelling from birkbeck dataset\n",
    "#get the real spelling from birkbeck data set\n",
    "cmu_luck_words = open('HBKcmu_luck_words.csv', 'w+')\n",
    "nb_misspelling = len(guess_dict)\n",
    "nb_good_correction = 0\n",
    "nb_luck= 0 # ie nb times real word is in the list of close phonemes\n",
    "\n",
    "for misspelling in list(guess_dict):\n",
    "    close_words= close_dict.get(misspelling)\n",
    "    if misspelling in reverse_dict :\n",
    "        realword = reverse_dict.get(misspelling).lower()\n",
    "\n",
    "        if realword in close_words :\n",
    "            nb_luck += 1\n",
    "            cmu_luck_words.write(realword +\",\"+ misspelling +\"\\n\")\n",
    "\n",
    "        guessword = guess_dict.get(misspelling).lower()\n",
    "        with open(\"HBKcmu_corrected_words.csv\", 'a', newline='') as csvfile:\n",
    "                writer =csv.writer(csvfile, delimiter=',')\n",
    "                writer.writerow([realword] + [misspelling] + [guessword])\n",
    "        #print(\"The misspelled word was {}, this solution corrected to {}. The correct word was {}\".format(misspelling, guessword, realword))\n",
    "        if(realword==guessword):\n",
    "            nb_good_correction += 1\n",
    "\n",
    "percentage_correct = nb_good_correction / nb_misspelling * 100\n",
    "print(\"correction percentage : \", percentage_correct)\n",
    "\n",
    "\n",
    "#GET THE PERCENTAGE OF CORRECTION OVER THE WORDS THAT ARE IN FRQUENCY AND CMU\n",
    "cmu_no_match = open('HBKcmu_no_match.csv', 'w+')\n",
    "cmu_good_correction = open('HBKcmu_good_correction.csv', 'w+')\n",
    "cmu_wrong_correction = open('HBKcmu_wrong_correction.csv', 'w+')\n",
    "\n",
    "#cmu_words1=open('cmu_corrected_words1.csv','r')\n",
    "cmu_words=open('HBKcmu_corrected_words.csv','r')\n",
    "\n",
    "i=0\n",
    "match=0\n",
    "no_match=0\n",
    "bad_corr =0\n",
    "\n",
    "for line in cmu_words:\n",
    "    i+=1\n",
    "    line = line.strip()\n",
    "    word, misspelling, guess = line.split(',')\n",
    "    if (misspelling != 'mot') :\n",
    "        if(word == guess):\n",
    "            match+=1\n",
    "            cmu_good_correction.write(word +\",\"+ misspelling +\",\"+ guess +\"\\n\")\n",
    "        else :\n",
    "            bad_corr +=1\n",
    "            cmu_wrong_correction.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "    else:\n",
    "        no_match+=1\n",
    "        cmu_no_match.write(word +\",\"+ misspelling+ \",\"+ guess +\"\\n\")\n",
    "        \n",
    "print(\"Correct word found : {}\".format(match))\n",
    "print(\"Guess word not in frequency or CMU dict : {}\".format(no_match))\n",
    "print(\"Bad correction : {}\".format(bad_corr))\n",
    "print(match +no_match+bad_corr)\n",
    "print(i) #lines in cmu_words\n",
    "\n",
    "luck_percentage = nb_luck/len(close_dict)*100\n",
    "print(\"Guess word was in close words {} times, ie in {} percent of the case\".format(nb_luck,luck_percentage))\n",
    "\n",
    "percentage = match / (match + bad_corr)*100\n",
    "print (\"New correction percentage {}\".format(percentage))\n",
    "\n",
    "cmu_words.close()    \n",
    "cmu_good_correction.close()\n",
    "cmu_luck_words.close()\n",
    "cmu_wrong_correction.close()\n",
    "cmu_no_match.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
